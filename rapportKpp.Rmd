---
title: 'Projet Kmeans ++ '
author: "Louan Ourvouai -- Valentin Buchon"
date: "02 Novembre 2022"
output:
  pdf_document: 
    fig_caption: yes
  html_document: default
fontsize: 10pt
---
<style type="text/css">
  body .main-container{
   max-width: 1100px !important;
   width: 1100px !important;
  }
  body {
    max-width: 1100px !important;
    margin = auto;
    padding: 5em;
  }
  body, td{
    font-size: 2em;
  }
  code.r{
    font-size: 1em;
  }
  pre{
    font-size: 1em;
    color: #191970;
  }
</style>


```{r color, include=FALSE}
colorize <- function(x, color) {
  if (knitr::is_latex_output()) {
    sprintf("\\textcolor{%s}{%s}", color, x)
  } else if (knitr::is_html_output()) {
    sprintf("<span style='color: %s;'>%s</span>", color, x)
  } else x
}
```
<!-- Does it show color? `r colorize("some words in red", "red")` -->

```{r setup, include = FALSE}
knitr::opts_chunk$set(error = TRUE)
knitr::opts_chunk$set(cache = TRUE)
knitr::opts_chunk$set(fig.align = "center")
knitr::opts_chunk$set(echo = TRUE, results="hide")
sol=FALSE
```


```{r echo=FALSE, message=FALSE, warning=FALSE}
library(tictoc)
library(mclust)
library(datasets)
library(gridExtra)
library(grid)

euclidean_dist <- function(x, y) sqrt(sum((x - y)^2))

# --------------------------------------------------
kmean2 <- function(X,K){
  len <- dim(X)[1]
  size <- dim(X)[2]
  C <- c(sample(1:len,K))
  centerMass <- matrix(nrow = K, ncol = size)
  meanMass <- matrix(0,nrow = K, ncol = size)
  for(mass in seq(1:K)){
    l <- C[mass]
    centerMass[mass,] <- X[l,]
  }
  C <- seq(1:K)
  while(euclidean_dist(centerMass,meanMass) > 0.1){
    cluster <- seq(1:len)
    for (i in seq(1:K)){ # Pour chaque i
      for (x in seq(1:len)){ # On va tester tous les x (oui c'est pas ouf)
        b <- TRUE
        loop <- seq(1:K)
        loop <- loop[!(seq(1:K) %in% i)]
        for (j in loop){ # On va faire la comparaison de la distance avec tous les autres
          if (euclidean_dist(centerMass[i,],X[x,])>euclidean_dist(centerMass[j,],X[x,])){
            b <- FALSE
          }
        }
        if(b){
          cluster[x] <- C[i]
        }
      }
    }
    meanMass <- matrix(0,nrow = K, ncol = size)
    for(i in seq(1:len)){
      for (c in C)
        if(cluster[i] == c){
          meanMass[c,] <- meanMass[c,] + X[i,]
        }
    }
    summ <- table(cluster)
    
    for(c in C){
      meanMass[c,] <- meanMass[c,]/summ[c]
    }
    
    aux <- centerMass
    centerMass <- meanMass
    meanMass <- aux
    
  }
  centerMass
}



phi <- function(X,C){
  res <- 0
  for (x in X){
    minimum <- .Machine$integer.max
    for (c in C){
      d <- euclidean_dist(x,c)
      d <- d^2
      if (d < minimum){
        minimum <- d
      }
    }
    res <- res + minimum
  }
  res
}

classif <- function(X,C){
  X <- as.matrix(X)
  lx <- dim(X)[1]
  res <- c()
  l = dim(C)[1]
  for (x in seq(1:lx)){
    minimum <- .Machine$integer.max
    idx <- 1
    for (i in seq(1:l)){
      d <- euclidean_dist(X[x,],C[i,])
      if (d < minimum){
        minimum <- d
        idx <- i
      }
    }
    res <- append(res,idx)
  }
  res
}


```
# Exercice 1

## Question 1
```{r}
kmeanspp <- function(X,K){
  len <- dim(X)[1]
  res <- c(sample(1:len,1))
  max <- K-1
  for (k in seq(1:max)){# Pour avoir K points
    dist_tab <- c() # Notre vecteur de proba distance
    idx <- seq(1:len)
    idx <- idx[!(seq(1:len) %in% res)]
    for (i in idx){
      dist <- .Machine$integer.max
      for(j in res){ # Pour tous les points c_i déjà sélectionner
        aux <- euclidean_dist(X[i,],X[j,])
        if (aux < dist){
          dist <- aux
        } # On prend le min de la distance
      }
      dist_tab <- append(dist_tab,dist)
    }
    dist_tab <- dist_tab^2/sum(dist_tab^2)
    # On doit choisir un point avec une proba pondéré par la distance
    c_k <- sample(idx,1,prob=dist_tab)
    res <- append(res,c_k)
  }
  res
}



kmean <- function(X,K){
  X <- as.matrix(X)
  len <- dim(X)[1]
  size <- dim(X)[2]
  C <- kmeanspp(X,K)
  centerMass <- matrix(0,nrow = K, ncol = size)
  meanMass <- matrix(0,nrow = K, ncol = size)
  for(mass in seq(1:K)){
    l <- C[mass]
    centerMass[mass,] <- X[l,]
  }
  C <- seq(1:K)
  while(euclidean_dist(centerMass,meanMass) > 0.001){
    cluster <- seq(1:len)
    for (i in seq(1:K)){ # Pour chaque i
      for (x in seq(1:len)){ # On va tester tous les x
        b <- TRUE
        loop <- seq(1:K)
        loop <- loop[!(seq(1:K) %in% i)]
        for (j in loop){ # On va faire la comparaison de la distance avec tous les autres
          if (euclidean_dist(centerMass[i,],X[x,])>euclidean_dist(centerMass[j,],X[x,])){
            b <- FALSE
          }
        }
        if(b){
          cluster[x] <- C[i]
        }
      }
    }
    meanMass <- matrix(0,nrow = K, ncol = size)
    for(i in seq(1:len)){
      for (c in C)
        if(cluster[i] == c){
          meanMass[c,] <- meanMass[c,] + X[i,]
        }
    }
    summ <- table(cluster)
    
    for(c in C){
      meanMass[c,] <- meanMass[c,]/summ[c]
    }
    
    aux <- centerMass
    centerMass <- meanMass
    meanMass <- aux
    
  }
  centerMass
}

```
## Question 2

```{r}
# n doit être un multiple de x
normx <- function(x,d,n){
  if (n%%x != 0){
    stop("n n est pas un multiple de x")
  }
  len <- n/x
  center <- matrix(nrow = x, ncol = d)
  res <- matrix(nrow = n, ncol = d)
  for (i in seq(1:x)){
    center[i,] <- runif(d,0,500)
    for (j in seq(1:d)){
      vec <- rnorm(len,mean=center[i,j],sd=1)
      debut <- ((i-1)*len)+1
      fin <- i*len
      res[debut:fin,j] <- vec
    }
    res[i*len,] <- center[i,]
  }
  res
}
```
## Question 3 
Voici nos résultats pour la comparaison avec NORM-10, NORM-25 pour kmeans et kmeans++. Nous retrouvons le même comportement avec les mêmes écarts relatifs que dans le papier de recherche. Cependant pour une raison encore incconu, nous n'obtenons pas les mêmes valeurs de $\phi$ que dans le papier de recherche.
quand $k=10$ pour NORM-10 et quand $k=25$ pour NORM-25, kmeans++ est nettement plus performant, il est plus rapide et plus précis. 
```{r echo=FALSE, message=FALSE, warning=FALSE}
# Variable importante

n = 1000
X <- normx(10,5,n)
# -------------------------------------#
# Pour k = 10


mean_kclas10 <- c()
mean_timek10 <- c()
for (loop in seq(1:20)){
  tic()
  #kpp <- kmean(X,10)
  #mean_kpp <- append(mean_kpp,phi(X,kpp)/n)
  kclas <- kmean2(X,10)
  mean_kclas10 <- append(mean_kclas10,phi(X,kclas)/n)
  time <- toc(quiet = TRUE)
  mean_timek10 <- append(mean_timek10, time$toc - time$tic)

}

#kclas <- kmeans(X,10,iter.max= 15, nstart = 1)

mean_kpp10 <- c()
mean_timekpp10 <- c()
for (loop in seq(1:20)){
  tic()
  kpp <- kmean(X,10)
  mean_kpp10 <- append(mean_kpp10,phi(X,kpp)/n)
  time <- toc(quiet = TRUE)
  mean_timekpp10 <- append(mean_timekpp10, time$toc - time$tic)
}

# -------------------------------------#
# Pour k = 25

mean_kclas25 <- c()
mean_timek25 <- c()
for (loop in seq(1:20)){
  tic()
  kclas <- kmean2(X,25)
  mean_kclas25 <- append(mean_kclas25,phi(X,kclas)/n)
  time <- toc(quiet = TRUE)
  mean_timek25 <- append(mean_timek25, time$toc - time$tic)

}


mean_kpp25 <- c()
mean_timekpp25 <- c()
for (loop in seq(1:20)){
  tic()
  kpp <- kmean(X,25)
  mean_kpp25 <- append(mean_kpp25,phi(X,kpp)/n)
  time <- toc(quiet = TRUE)
  mean_timekpp25 <- append(mean_timekpp25, time$toc - time$tic)
}

# -------------------------------------#
# Pour k = 50

mean_kclas50 <- c()
mean_timek50 <- c()
for (loop in seq(1:20)){
  tic()
  kclas <- kmean2(X,50)
  mean_kclas50 <- append(mean_kclas50,phi(X,kclas)/n)
  time <- toc(quiet = TRUE)
  mean_timek50 <- append(mean_timek50, time$toc - time$tic)

}

mean_kpp50 <- c()
mean_timekpp50 <- c()
for (loop in seq(1:20)){
  tic()
  kpp <- kmean(X,50)
  mean_kpp50 <- append(mean_kpp50,phi(X,kpp)/n)
  time <- toc(quiet = TRUE)
  mean_timekpp50 <- append(mean_timekpp50, time$toc - time$tic)
}
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
library('grid')
k <- c(10,25,50)
mean_phi_k <- c(mean(mean_kclas10),mean(mean_kclas25),mean(mean_kclas50))
mean_phi_kpp <- c(mean(mean_kpp10),mean(mean_kpp25),mean(mean_kpp50))
min_phi_k <- c(min(mean_kclas10),min(mean_kclas25),min(mean_kclas50))
min_phi_kpp <- c(min(mean_kpp10),min(mean_kpp25),min(mean_kpp50))
time_k <- c(mean(mean_timek10),mean(mean_timek25),mean(mean_timek50))
time_kpp <- c(mean(mean_timekpp10),mean(mean_timekpp25),mean(mean_timekpp50))

final2 = data.frame(k,mean_phi_k,mean_phi_kpp,min_phi_k,min_phi_kpp,time_k,time_kpp)
g2 <- tableGrob(final2, rows = NULL)
grid.newpage()
grid.draw(g2)
```
Tableau comparatif de kmeans++ et kmeans pour NORM-25 avec n = 1000 et d = 5
```{r echo=FALSE, message=FALSE, warning=FALSE}
# Variable importante

n = 1000
X <- normx(25,5,n)
# -------------------------------------#
# Pour k = 10


mean_kclas10 <- c()
mean_timek10 <- c()
for (loop in seq(1:20)){
  tic()
  #kpp <- kmean(X,10)
  #mean_kpp <- append(mean_kpp,phi(X,kpp)/n)
  kclas <- kmean2(X,10)
  mean_kclas10 <- append(mean_kclas10,phi(X,kclas)/n)
  time <- toc(quiet = TRUE)
  mean_timek10 <- append(mean_timek10, time$toc - time$tic)

}

#kclas <- kmeans(X,10,iter.max= 15, nstart = 1)

mean_kpp10 <- c()
mean_timekpp10 <- c()
for (loop in seq(1:20)){
  tic()
  kpp <- kmean(X,10)
  mean_kpp10 <- append(mean_kpp10,phi(X,kpp)/n)
  time <- toc(quiet = TRUE)
  mean_timekpp10 <- append(mean_timekpp10, time$toc - time$tic)
}

# -------------------------------------#
# Pour k = 25

mean_kclas25 <- c()
mean_timek25 <- c()
for (loop in seq(1:20)){
  tic()
  kclas <- kmean2(X,25)
  mean_kclas25 <- append(mean_kclas25,phi(X,kclas)/n)
  time <- toc(quiet = TRUE)
  mean_timek25 <- append(mean_timek25, time$toc - time$tic)

}


mean_kpp25 <- c()
mean_timekpp25 <- c()
for (loop in seq(1:20)){
  tic()
  kpp <- kmean(X,25)
  mean_kpp25 <- append(mean_kpp25,phi(X,kpp)/n)
  time <- toc(quiet = TRUE)
  mean_timekpp25 <- append(mean_timekpp25, time$toc - time$tic)
}

# -------------------------------------#
# Pour k = 50

mean_kclas50 <- c()
mean_timek50 <- c()
for (loop in seq(1:20)){
  tic()
  kclas <- kmean2(X,50)
  mean_kclas50 <- append(mean_kclas50,phi(X,kclas)/n)
  time <- toc(quiet = TRUE)
  mean_timek50 <- append(mean_timek50, time$toc - time$tic)

}

mean_kpp50 <- c()
mean_timekpp50 <- c()
for (loop in seq(1:20)){
  tic()
  kpp <- kmean(X,50)
  mean_kpp50 <- append(mean_kpp50,phi(X,kpp)/n)
  time <- toc(quiet = TRUE)
  mean_timekpp50 <- append(mean_timekpp50, time$toc - time$tic)
}
```

```{r echo=FALSE}
library('grid')
k <- c(10,25,50)
mean_phi_k <- c(mean(mean_kclas10),mean(mean_kclas25),mean(mean_kclas50))
mean_phi_kpp <- c(mean(mean_kpp10),mean(mean_kpp25),mean(mean_kpp50))
min_phi_k <- c(min(mean_kclas10),min(mean_kclas25),min(mean_kclas50))
min_phi_kpp <- c(min(mean_kpp10),min(mean_kpp25),min(mean_kpp50))
time_k <- c(mean(mean_timek10),mean(mean_timek25),mean(mean_timek50))
time_kpp <- c(mean(mean_timekpp10),mean(mean_timekpp25),mean(mean_timekpp50))


final = data.frame(k,mean_phi_k,mean_phi_kpp,min_phi_k,min_phi_kpp,time_k,time_kpp)
g <- tableGrob(final, rows = NULL)

grid.newpage()
grid.draw(g)
```
Tableau comparatif de kmeans++ et kmeans pour NORM-25 avec n = 1000 et d = 5

# Exercice 2

## Question 1
Voici le cardinal de chacun des 3 sous ensemble :
```{r, results='asis', echo = FALSE}
data(iris)

kpp <- kmean(iris[,1:4],3)
k <- kmeans(iris[,1:4],3, nstart = 5)
kclust = Mclust(iris[-5],G=3,modelNames="VEV")
clustkpp <- classif(iris[-5],kpp)
cat("\n\n")
cat("Nombre de cluster pour kmeans++ : ",table(clustkpp))
cat("\n\n")
cat("Nombre de cluster pour kmeans : ",table(k$cluster))
cat("\n\n")
cat("Nombre de cluster pour Hclust : ",table(kclust$classification))
```

## Question 2

```{r graph_code,echo=FALSE}
pcaIris <- prcomp(iris[-5])

plot(pcaIris$x[,1],pcaIris$x[,2],main = "Représentation des différents cluster avec Kmeans++ et une PCA",xlab = "PCA1", ylab= "PCA2",col=clustkpp)
plot(pcaIris$x[,1],pcaIris$x[,2],main = "Représentation des différents cluster avec Kmeans et une PCA",xlab = "PCA1", ylab= "PCA2",col=k$cluster)
plot(pcaIris$x[,1],pcaIris$x[,2],main = "Représentation des différents cluster avec Mclust et une PCA",xlab = "PCA1", ylab= "PCA2",col=kclust$classification)
```
## Question 3
Kmeans++ et Kmeans donnent des résultats quasiement similaire, Mclust lui est un peu différents. La non différence de Kmeans++ et Kmeans semble logique, Kmeans++ permet de converger plus vite et déviter certaines abérations, mais sinon ce sont les mêmes algorithmes. Mclust est pas nature différents.